---
title: "Unsupervised"
author: "Mihir Kulkarni"
date: "2023-12-12"
output: html_notebook
---

# Part III: Exploring the sub-clusters of the cirrhosis data using unsupervised learning

In this section, we sought to if there are sub-collections of patients. We expect sub-collections to mimic medical definitions of the stages of Biliary Cirrhosis but are curious to see if clustering can reveal some newer observations.

## Introduction

Biliary Cirrhosis patients are typically clustered in four main clusters ([Source](https://www.healthline.com/health/primary-biliary-cirrhosis#stages){.uri}):

-   Stage 1: There's inflammation and damage to the walls of medium-sized bile ducts.

-   Stage 2: There's blockage of the small bile ducts.

-   Stage 3: This stage marks the beginning of scarring.

-   Stage 4: Cirrhosis has developed. This permanent, severe, scarring and damage to the liver.

In this section we will be using clustering on our data. K-means Clustering is an unsupervised learning technique where data points are grouped based on their similarities. It's commonly used to identify patterns and structures within datasets without prior knowledge of the groups. The main advantage of clustering is its ability to discover hidden patterns in data. However, a significant drawback is the subjectivity in defining the 'similarity' criteria, which can lead to varying results and interpretations.

[![K-means clustering ([Source](https://medium.datadriveninvestor.com/k-means-clustering-4a700d4a4720))](1*fz-rjYPPRlGEMdTI-RLbDg.png)](https://medium.datadriveninvestor.com/k-means-clustering-4a700d4a4720)

An important motivation for this part of the study is explore how does "Stage" which is typically defined based on medical professionals' observations compares to the data that we have in this data set.

## Pre-processing the data

We had to pre-process the data for the best performance. First, we removed the 'Stage' column to avoid using outcome-related features in the unsupervised learning. The rows with N/A values were also removed. Lastly, we transformed various categorical variables into numeric formats, which is necessary for clustering algorithms.

```{r}
#do the ml, take about observational stages vs now quantify, look into the different variables and what they mean.
cirrhosisCluster <- cirrhosis
cirrhosisCluster2 <- na.omit(cirrhosis)

cirrhosisCluster <- cirrhosisCluster %>%                 
                                  dplyr::select(-Stage)     
                                              
cirrhosisCluster <- na.omit(cirrhosisCluster) #cannot have NA values in clustering

cirrhosisCluster$Age_Years <- round(cirrhosisCluster$Age_Years) #round age to whole numbers


#reode sex... recode others later if need be #female is 0

#cirrhosisCluster  <- cirrhosisCluster %>%
#  select( -c(Status, Drug, Edema)) %>%
  
# mutate(Sex = ifelse(Sex == 'Female', 0, 1))
     
      
  cirrhosisCluster  <- cirrhosisCluster %>%
    mutate(Sex = ifelse(Sex == 'Female', 0, 1)) %>%
          mutate(Transplant = ifelse(Status == "CL", 1, 0)) %>%
              mutate(Status = ifelse(Status %in% c('C', 'CL'), 0 , 1)) %>%
                    mutate(Drug = ifelse(Drug == "D-penicillamine", 0, 1)) %>%
                        mutate(EdemaDiurectics = ifelse(Edema %in% c('S', 'Y'), 1, 0)) %>%
                              mutate(NoEdemaORD = ifelse(Edema == 'N' , 1, 0)) %>%
                                        mutate(EdemaANDD = ifelse(Edema == "Y", 1, 0)) %>%
                                                mutate(EdemaORD = ifelse(Edema == "S", 1, 0)) %>%
                                                                              dplyr::select(-Edema)
                                        
                                    
                          

#Data is already factored
     
#mutate(Sex = ifelse(Sex == 'Female', 0, 1)) %>%
  
   #mutate(Status = ifelse(Status %in% c('C', 'CL'), 0 , 1)) %>%
          #    mutate(Drug = ifelse(Drug == "D-penicillamine", 0, 1))

  
#???:
  
#make column yes no edema #then yes no under treatment

#same for transplant stuff
```

```{r}
distCirrhosis <- dist(
  x = cirrhosisCluster,
  method = "euclidean"
)

```

## Methodology

To apply the k-means algorithm. A mixed hierarchical and non-hierarchical was applied. This was done using the hkmeansm module, with k = 4 as our initial value. Based on the data properties, the euclidean (L2) distance works best.

```{r}

hybridCirrhosis <- hkmeans(
  x = cirrhosisCluster,
  k = 4,
  hc.metric = "euclidean",
  hc.method = "ward.D",
  iter.max = 10
)

```

## Results

We were able to visualize the results of the k-means algorithm. The first step was making a color palette and plotting the dendrogram tree.

```{r}

StagesPalette <- c("#AA336A", "#770737", "#40B5AD", "#009E60", "#9FE2BF")

```

```{r}
## MAKE A NEW PALLETE TO VISUALIZE
# Plot the initial dendrogram for hybrid approach ----
set.seed(380)
hkmeans_tree(
  hkmeans = hybridCirrhosis,
  rect.col = StagesPalette,
  cex = 0.4,
  main = "Initial Hierarchical Clusters"
)

```

As, you can see, the model was able to create clear clusters for the data. However, it is important to find the best value of k to get the optimal clusters. To do this we can use a scree plot. Here, we\'re looking for the number of clusters that corresponds to the \"elbow\".

```{r}
# Create scree plot for choosing k ----
library(factoextra)
set.seed(380)
fviz_nbclust(
  x = cirrhosisCluster,
  diss = NULL,
  FUNcluster = kmeans,
  method = "wss",
  k.max = 10
)


```

From this, we identified that 5 was the ideal value of k, where the Total Within [Cluster] Sums of Squares begins leveling off. Let us create a new k-means model with k = 5. We can plot this refined model, with a format more easy to visualize.

```{r}

hybridCirrhosis2 <- hkmeans(
  x = cirrhosisCluster,
  k = 5,
  hc.metric = "euclidean",
  hc.method = "ward.D",
  iter.max = 10
)

```

```{r}
# Plot the final dendrogram for hybrid approach ----
# library(factoextra)
fviz_dend(
  x = hybridCirrhosis2,
  cex = 0.4,
  palette = StagesPalette,
  rect = FALSE,
  horiz = TRUE,
  repel = TRUE,
  main = "Final Dendrogram"
)



```

As you can see, the 5 clusters were identified, which are color coded in our updated diagram.

Lastly, let us plot these clusters. Here is a plot of the initial model where k = 4

```{r}
# Plot the final clustering for hybrid approach ----
# library(factoextra)
fviz_cluster(
  object = hybridCirrhosis,
  stand = FALSE,
  geom = "point",
  main = "Hybrid Cluster Plot - Initial model"
) +
  scale_color_manual(values = StagesPalette) +
  scale_fill_manual(values = StagesPalette) +
  theme_bw() 

```

We can also plot our refined model, as you can see the plot below identifies 5 clear clusters.

```{r}

# Plot the final clustering for hybrid approach ----
# library(factoextra)
fviz_cluster(
  object = hybridCirrhosis2,
  stand = FALSE,
  geom = "point",
  main = "Hybrid Cluster Plot - Refined model"
) +
  scale_color_manual(values = StagesPalette) +
  scale_fill_manual(values = StagesPalette) +
  theme_bw() 

```

Now we can go back to our initial goal: comparing how the custers compare to the Stage variable

```{r}
cirrhosisCluster2$cluster <- hybridCirrhosis$cluster
# Calculate mean (or median, etc.) for each variable in each cluster
library(dplyr)
cluster_summary <- cirrhosisCluster2 %>%
  group_by(cluster) %>%
  summarise_all(funs(mean(., na.rm = TRUE))) # Replace mean with median or any other function as necessary
kable(cluster_summary %>% dplyr::select(-Status, -Drug, - Sex, -Edema, -Stage), label = "Cluster Summary")
ggplot(cirrhosisCluster2, aes(x = factor(cluster), fill = factor(Stage))) +
  geom_bar(position = "dodge") +
  labs(title = "Distribution of Stages within Clusters",
       x = "Cluster",
       y = "Count",
       fill = "Stage") +
  theme_minimal()

```
